
;; DEFINICIÓN DE LA RED
def create_simple_pm():
    #modelo simple de pm
    #se usa la sigmoide pero puede utilizarse la función de activación relu
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.BatchNormalization(input_shape=(32, 32, 3)))
    model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3), name="Input_layer"))

    model.add(tf.keras.layers.Dense(2500, activation='relu', name="Hidden_layer"))
    model.add(tf.keras.layers.Dense(2000, activation='relu', name="Hidden_layer1"))
    model.add(tf.keras.layers.Dense(1500, activation='relu', name="Hidden_layer2"))
    model.add(tf.keras.layers.Dense(1000, activation='relu', name="Hidden_layer3"))
    model.add(tf.keras.layers.Dense(500, activation='relu', name="Hidden_layer4"))
    
    
    
    model.add(tf.keras.layers.Dense(10, activation='softmax', name="Output_layer"))
    return model

;; MODEL COMPILE
model = create_simple_pm() 
model.compile(
      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),
      
      loss='sparse_categorical_crossentropy',
      metrics=['sparse_categorical_accuracy'])


;; MODEL FIT
historico = model.fit(train_images, train_labels, epochs=15, validation_freq=1,
                      validation_data=(test_images, test_labels))